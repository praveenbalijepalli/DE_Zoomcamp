## Batch Processing

   ```
    Operating System:               Windows
    Code:                           https://github.com/praveenbalijepalli/DE_Zoomcamp/blob/main/Week5/week_5_batch_processing/week_5_batch_processing.ipynb
    Environment Setup:              conda create -n DE python=3.9
                                    conda activate DE
    Packages Installed              conda install -c conda-forge numpy pandas findspark
                                    
    Spark Installation:             https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_5_batch_processing/setup/windows.md

    Connecting pyspark to Spark:    https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_5_batch_processing/setup/pyspark.md
 ```
 
 Alternatively, installing findspark and using it like shown in the [code](https://github.com/praveenbalijepalli/DE_Zoomcamp/blob/main/Week5/week_5_batch_processing/week_5_batch_processing.ipynb ) can help us use pyspark to work with spark while in our environment.
 
  
